## Producer

### 파티셔너
* 프로듀서는 토픽으로 메세지를 보낼 때 해당 토픽의 어느 파티션으로 메세지를 보내야 할지를 결정해야한다.
* 이때, 파티셔너는 데이터를 어떤 파티션에 넣을지 결정하는 역할을 한다.
* 프로듀서가 파티션을 결정하는 알고리즘은 기본적으로 메세지의 키를 해싱하여 파티션을 결정한다.
* 따라서, 메세지의 키 값이 동일하다면 해당 메세지들은 모두 동일한 파티션에 전송된다.
* 다만, 파티션 수가 변경됨과 동시에 메세지의 키와 매핑된 해시 테이블이 변경될 수 있기 때문에 파티션의 수를 늘리면 다른 파티션으로 전송될 수 있다.

### 라운드 로빈 전략
* 메세지의 키 값을 지정하지 않으면 예전에는 기본적으로 라운드 로빈 방식으로 메세지를 전송했다.
* 근데 이 방식은 문제가 있었다.
* 보통 파티셔너를 거친 메세지들은 배치 처리를 위해 프로듀서의 버퍼 메모리 영역에서 잠시 대기한 후 카프카로 전송된다.
* 만약 배치 전송을 위한 최소 레코드(메세지) 수가 3으로 설정되어 있고 파티션의 수가 3개라고 가정했을 때, 메세지가 총 5개 전송되었고 라운드 로빈 방식이라면 계속해서 카프카로 전송되지 못한 채 프로듀서 내에서 대기할 것 이다.
* 이러한 문제를 해결하기 위해 스티키 파티셔닝이 나왔다.

### 스티키 파티셔닝 전략
* 스티키 파티셔닝 전략이란 하나의 파티션에 메세지 수를 먼저 채워서 카프카로 빠르게 배치 전송하는 전략이다.
* Confluent 에서는 라운드 로빈 방식에 비해 30% 이상 지연시간이 감소하고 프로듀서의 CPU 사용률도 줄어드는 효과를 얻었다고한다.
* https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner/

### 배치
* 프로듀서에서는 처리량을 높이기 위해 배치 전송을 권장한다.
* buffer.memory : 카프카로 메세지들을 전송하기 위해 담아두는 프로듀서의 버퍼 메모리 옵션 (기본값 32MB)
* batch.size : 배치 전송을 위해 메세지들을 묶는 단위를 설정하는 배치 크기 옵션 (기본값 16KB)
* linger.ms : 배치 전송을 위해 메세지들을 묶는 시간을 설정하는 옵션 (기본값 0)
* 지연 없는 전송이 목표라면 batch.size 와 linger.ms 를 작게 설정해야 한다.
* 처리량을 높이려면 batch.size 와 linger.ms 를 늘려야 한다.
* 높은 처리량을 목표로 할 경우에는 buffer.memory 가 커야하고 반드시 buffer.memory 는 batch.size 보다 커야한다.
* 예를 들어, batch.size 가 16KB 이고 파티션이 3개일 때, 16KB * 3 = 48KB 이므로 buffer.memory 는 48KB 보다 커야한다.
* 왜냐하면 프로듀서는 전송에 실패하면 재시도를 수행하는데, 이때 재시도를 위해 메모리를 사용하기 때문이다.

### 메세지 전송 방식
* 적어도 한 번 전송
* 최대 한 번 전송
* 정확히 한 번 전송

### 적어도 한 번 전송
* 예시
  * 프로듀서가 브로커의 특정 토픽으로 메세지 A 를 전송한다.
  * 브로커는 메세지 A 를 기록하고 잘 받았다는 ACK 를 프로듀서에게 응답한다.
  * 브로커의 ACK 를 받은 프로듀서는 다음 메세지인 메세지 B 를 전송한다.
  * 브로커는 메세지 B 를 기록하고 잘 받았다는 ACK 를 프로듀서에게 응답하려 했지만 네트워크 오류로 전달되지 않았다.
  * ACK 를 받지 못한 프로듀서는 메세지 B 를 재전송한다.
* 위 상황처럼 네트워크의 회선 장애나 기타 장애 상황에 따라 일부 메세지 중복이 발생할 수 있지만, 최소한 하나의 메세지는 반드시 보장하는 방법
* 카프카의 기본적인 동작 방식

### 최대 한 번 전송
* 예시
  * 프로듀서가 브로커의 특정 토픽으로 메세지 A 를 전송한다.
  * 브로커는 메세지 A 를 기록하고 잘 받았다는 ACK 를 프로듀서에게 응답한다.
  * 브로커의 ACK 를 받은 프로듀서는 다음 메세지인 메세지 B 를 전송한다.
  * 브로커는 메세지 B 를 기록하고 잘 받았다는 ACK 를 프로듀서에게 응답하려 했지만 네트워크 오류로 전달되지 않았다.
  * 프로듀서는 브로커가 메세지 B 를 받았다고 가정하고 메세지 C 를 전송한다.
* 사실 최대 한 번 전송에서는 ACK 를 응답하는 과정은 필요 없다. (예시에만 등장)
* 일부 메세지가 손실되더라도 높은 처리량을 필요로 하는 대량의 로그 수집같은 환경에서 사용 하곤 한다.

### 중복 없는 전송
* 예시
  * 프로듀서가 브로커의 특정 토픽으로 메세지 A 를 전송한다. 이때 PID 와 메세지 번호를 헤더에 포함해서 전달한다.
  * 브로커는 메세지 A 를 기록하고 PID 와 메세지 번호를 메모리에 기록한다. 그리고 ACK 를 프로듀서에게 응답한다.
  * 프로듀서는 다음 메세지인 메세지 B 를 전송한다. 이때 PID 와 메세지 번호를 헤더에 포함해서 전달한다.
  * 브로커는 메세지 B 를 기록하고 PID 와 메세지 번호를 메모리에 기록한다. 그리고 ACK 를 프로듀서에게 응답하려했지만 네트워크 오류로 전달되지 않았다.
  * ACK 를 받지 못한 프로듀서는 브로커가 메세지 B 를 받지 못했다고 판단하여 재전송한다.
  * 브로커는 이미 메세지 B 를 기록했기 때문에 PID 와 메세지 번호를 비교해서 이미 있다면 ACK 만 응답한다.
* 중복 없는 전송 방식은 매우 유용해 보이지만, 결국 오버헤드는 발생할 수 밖에 없다.
* 다만, Confluent 에 따르면 성능이 20% 증가했기에 성능에 그다지 민감하지 않다면 해당 설정을 사용하는 것이 좋을 것 같다.
* https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/
* 옵션
  * enable.idempotence : 중복 없는 전송을 위한 옵션 (Spring Kafka 3.x 부터 기본값 true)
  * max.in.flight.requests.per.connection : ACK 를 받지 않은 상태에서 하나의 커넥션에서 보낼 수 있는 최대 요청 수 (기본값 5)
  * acks : all 로 설정해야한다.
  * retries : 재시도 횟수, ACK 를 받지 못한 경우 재시도를 해야하므로 0보다 큰 값으로 설정

### 정확히 한 번 전송
* 중복 없는 전송 방식이 정확히 한 번 전송하는 것은 아니다.
* 카프카 트랜잭션을 활용하면 정확히 한 번 전송할 수 있다.
* 프로듀서가 보내는 메세지들은 원자적으로 처리되어 전송에 성공하거나 실패하게 된다.
* 트랜잭션을 사용하면 전체 consume-transform-produce 프로세스를 하나의 원자 트랜잭션으로 취급할 수 있으며, 모든 단계가 성공할 때만 커밋된다.
* 어느 지점에서든 실패가 발생하면 전체 트랜잭션이 중단된다. 이렇게 하면 메세지가 중복되거나 데이터가 더 심각하게 손상되는 것을 방지할 수 있다.
* **transactional.id**는 프로듀서 수준에서 설정되며, 트랜잭션 프로듀서를 애플리케이션이 재시작된 후에도 식별할 수 있도록 한다.
* **transaction coordinator**는 트랜잭션 메타데이터를 관리하고 전체 트랜잭션 프로세스를 감독하는 브로커 프로세스이다.
  * 전송된 메세지를 관리하며, 커밋 또는 중단 등을 표시한다.
  * 트랜잭션 로그를 내부 토픽인 __transaction_state 에 저장한다.
* __transaction_state 는 내부 토픽이고 이 역시 토픽이므로 파티션 수와 리플리케이션 팩터 수가 존재하며 브로커의 설정을 통해 변경가능하다.
* 프로듀서가 직접 __transaction_state 에 기록하는게 아니라 transaction coordinator 에게 알리고, 모든 정보는 transaction coordinator 가 직접 기록한다.
* transaction coordinator 는 transactional.id 의 해시를 가져와서 이를 사용하여 __transaction_state 토픽의 파티션을 결정합니다. 이곳에 트랜잭션 로그를 저장한다.

#### 초기화
* 트랜잭션을 초기화할 때 트랜잭션 코디네이터는 PID(Producer ID)와 TID(Transaction ID)를 매핑하고, 트랜잭션 로그에 기록한다.
* 그 다음 PID 에포크를 한 단계 올리고 PID 에포크가 올라감에 따라 이전의 동일한 PID 와 이전 에포크에 대한 쓰기 요청은 모두 무시된다.

#### 트랜잭션 시작
* 트랜잭션이 시작되면 프로듀서는 토픽 파티션 정보를 트랜잭션 코디네이터에게 전달하고, 코디네이터는 트랜잭션 로그에 기록한다.
* 이 때, TID 와 파티션 정보가 로그에 기록되며 트랜잭션 상태를 Ongoing 으로 표시한다. 이 때, 기본값인 1분동안 상태 업데이트가 없으면 트랜잭션은 실패로 처리된다.
* 메세지 전송을 할 때 메세지가 저장되는 브로커와 PID, TID, 파티션정보(상태)가 저장되는 브로커는 다르다.
* 왜냐하면 트랜잭션 코디네이터가 있는 브로커와 프로듀서가 메세지를 전송하는 브로커는 서로 다르기 때문이다.

#### 트랜잭션 종료
* 메세지 전송을 완료하면 프로듀서는 commit 혹은 abort 메서드 중 하나를 무조건 호출해야한다.
* 해당 메세드를 통해 트랜잭션의 종료를 코디네이터에게 알린다.
* 트랜잭션 코디네이터는 두 단계의 커밋과정을 거친다.
* 첫 번째로 트랜잭션 로그에 해당 트랜잭션에 대한 PrepareCommit 또는 PrepareAbort 를 기록한다.
* 두 번째로 트랜잭션 로그에 기록된 토픽의 파티션에 트랜잭션 커밋 또는 롤백 표시를 기록한다.
* 예를 들어, 특정 파티션에 메세지를 전송했고, 해당 메세지의 오프셋이 1이라고 가정했을 때 코디네이터는 해당 파티션에 트랜잭션 커밋 표시를 기록하고 이 때 파티션의 마지막 오프셋은 2로 증가한다.
* 트랜잭션이 성공하지 않으면 오프셋은 증가할 일이 없으며 이렇게 되면 컨슈머에 절대 반환되지 않는다.

#### 트랜잭션 완료
* 트랜잭션 코디네이터는 완료됨이라고 트랜잭션 로그에 기록한다.
* 프로듀서에게 해당 트랜잭션이 완료됨을 알린 다음 해당 트랜잭션에 대한 처리는 모두 마무리된다.
* 트랜잭션을 이용한 컨슈머는 read_committed 레벨로 설정해야한다.


